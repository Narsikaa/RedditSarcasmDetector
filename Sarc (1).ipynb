{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sar_acc = pd.read_csv('train-balanced-sarcasm.csv', nrows=200000)\n",
    "sar_acc.dropna(subset=['comment'], inplace=True)\n",
    "import re\n",
    "sar_acc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sar_acc['length'] = sar_acc['comment'].str.len()\n",
    "sar_acc['num_words'] = sar_acc['comment'].apply(lambda x: len(str(x).split()))\n",
    "sar_acc.drop(['author','subreddit','score','ups','downs','date','created_utc','parent_comment'],axis=1,inplace = True)\n",
    "sar_acc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sar_acc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sar_acc['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "sar_acc_tar = sar_acc['label'].value_counts()\n",
    "labels = ['Acclaim', 'Sarcastic']\n",
    "sizes = (np.array((sar_acc_tar / sar_acc_tar.sum())*100))\n",
    "colors = ['light-blue', 'light-red']\n",
    "\n",
    "trace = go.Pie(labels=labels, values=sizes, opacity = 0.8, hoverinfo='label+percent',\n",
    "               marker=dict(colors=colors, line=dict(color='#FFFFFF', width=2)))\n",
    "layout = go.Layout(\n",
    "    title='Sarcastic Vs Acclaim'\n",
    ")\n",
    "data = [trace]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, filename=\"Sa_Ac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sar_list = sar_acc[sar_acc.label==1]\n",
    "sar_list.reset_index(drop=True, inplace=True)\n",
    "acc_list = sar_acc[sar_acc.label==0]\n",
    "acc_list.reset_index(drop=True, inplace=True)\n",
    "sar_comments = []\n",
    "for rows in range(0,sar_list.shape[0]):\n",
    "    head_txt = sar_list.comment[rows]\n",
    "    head_txt = head_txt.split(\" \")\n",
    "    sar_comments.append(head_txt)\n",
    "    \n",
    "import itertools\n",
    "sar_list = list(itertools.chain(*sar_comments))\n",
    "\n",
    "acc_comments = []\n",
    "for rows in range(0,acc_list.shape[0]):\n",
    "    head_txt = acc_list.comment[rows]\n",
    "    head_txt = head_txt.split(\" \")\n",
    "    acc_comments.append(head_txt)\n",
    "    \n",
    "acc_list = list(itertools.chain(*acc_comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "sar_list_restp = [word for word in sar_list if word.lower() not in stopwords]\n",
    "acc_list_restp = [word for word in acc_list if word.lower() not in stopwords]\n",
    "print(\"Length of original Sarcasm list: {0} words\\n\"\n",
    "      \"Length of Sarcasm list after stopwords removal: {1} words\"\n",
    "      .format(len(sar_list), len(sar_list_restp)))\n",
    "\n",
    "print(\"==\"*40)\n",
    "\n",
    "print(\"Length of original Acclaim list: {0} words\\n\"\n",
    "      \"Length of Acclaim list after stopwords removal: {1} words\"\n",
    "      .format(len(acc_list), len(acc_list_restp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_words = sar_acc['comment'].str.split(expand=True).unstack().value_counts()\n",
    "data = [go.Bar(x=all_words.index.values[2:50], \n",
    "               y=all_words.values[2:50],\n",
    "               marker = dict(colorscale='Viridis',\n",
    "                             color = all_words.values[2:100]),\n",
    "               text = 'Word counts')]\n",
    "layout = go.Layout(title = 'Frequent occuring words in the comments')\n",
    "fig = go.Figure(data = data, layout=layout)\n",
    "iplot(fig, filename='basic-bar')               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "sar_cntr = Counter(sar_list_restp)\n",
    "acc_cntr = Counter(acc_list_restp)\n",
    "\n",
    "sar_cntr_df = pd.DataFrame(list(sar_cntr.items()), columns = ['Words','Freq'])\n",
    "sar_cntr_df = sar_cntr_df.sort_values(by=['Freq'], ascending = False)\n",
    "acc_cntr_df = pd.DataFrame(list(acc_cntr.items()), columns = ['Words','Freq'])\n",
    "acc_cntr_df = acc_cntr_df.sort_values(by=['Freq'], ascending = False)\n",
    "\n",
    "sar_cntr_df_50 = sar_cntr_df.head(50)\n",
    "acc_cntr_df_50 = acc_cntr_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the top 50 Sarcasm Vs Acclaim\n",
    "from plotly import tools\n",
    "sar_tr  = go.Bar(\n",
    "    x=sar_cntr_df_50['Freq'],\n",
    "    y=sar_cntr_df_50['Words'],\n",
    "    name='Sarcasm',\n",
    "    marker=dict(\n",
    "        color='rgba(155, 89, 182, 0.6)',\n",
    "        line=dict(\n",
    "            color='rgba(155, 89, 182, 1.0)',\n",
    "            width=.3,\n",
    "        )\n",
    "    ),\n",
    "    orientation='h',\n",
    "    opacity=0.6\n",
    ")\n",
    "acc_tr  = go.Bar(\n",
    "    x=acc_cntr_df_50['Freq'],\n",
    "    y=acc_cntr_df_50['Words'],\n",
    "    name='Acclaim',\n",
    "    marker=dict(\n",
    "        color='rgba(88, 214, 141, 0.6)',\n",
    "        line=dict(\n",
    "            color='rgba(88, 214, 141, 1.0)',\n",
    "            width=.3,\n",
    "        )\n",
    "    ),\n",
    "    orientation='h',\n",
    "    opacity=0.6\n",
    ")\n",
    "\n",
    "fig = tools.make_subplots(rows=2, cols=1, subplot_titles=('Top 50 Most occuring words in Sarcastic Comments',\n",
    "                                                          'Top 50 Most occuring words in Acclaim Comments'))\n",
    "\n",
    "fig.append_trace(sar_tr, 1, 1)\n",
    "fig.append_trace(acc_tr, 2, 1)\n",
    "\n",
    "\n",
    "fig['layout'].update(height=1200, width=800)\n",
    "\n",
    "iplot(fig, filename='sar_vs_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemm = WordNetLemmatizer()\n",
    "sar_wost_lem = []\n",
    "for batch in sar_comments:\n",
    "    sar_list_restp = [word for word in batch if word.lower() not in stopwords]\n",
    "    sar_list_lemm = [lemm.lemmatize(word) for word in sar_list_restp]\n",
    "    sar_wost_lem.append(sar_list_lemm)\n",
    "acc_wost_lem = []\n",
    "for batch in acc_comments:\n",
    "    acc_list_restp = [word for word in batch if word.lower() not in stopwords]\n",
    "    acc_list_lemm = [lemm.lemmatize(word) for word in acc_list_restp]\n",
    "    acc_wost_lem.append(acc_list_lemm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "sar_list_wd = list(itertools.chain(*sar_wost_lem))\n",
    "from wordcloud import WordCloud\n",
    "sar_cloud = WordCloud(background_color='black', width = 5000, height = 2000).generate(\" \".join(sar_list_wd))\n",
    "plt.imshow(sar_cloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_list_wd = list(itertools.chain(*acc_wost_lem))\n",
    "acc_cloud = WordCloud(background_color='black',width = 2000, height = 1000).generate(\" \".join(acc_list_wd))\n",
    "plt.imshow(acc_cloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = sar_acc.comment.astype('str')\n",
    "X.str.lower()\n",
    "Y = sar_acc.label\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "Y = Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "max_words = 1000\n",
    "max_len = 300\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequence_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = RNN()\n",
    "model1.summary()\n",
    "model1.compile(loss='binary_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "history = model1.fit(sequence_matrix,Y_train,batch_size=200,epochs=5,\n",
    "          validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(15,5))\n",
    "fig.suptitle(\"Performance of RNN Model with RELU activation, Binary crossentropy and RMSprop\")\n",
    "ax1.plot(history.history['acc'])\n",
    "ax1.plot(history.history['val_acc'])\n",
    "vline_cut = np.where(history.history['val_acc'] == np.max(history.history['val_acc']))[0][0]\n",
    "ax1.axvline(x=vline_cut, color='k', linestyle='--')\n",
    "ax1.set_title(\"Model Accuracy\")\n",
    "ax1.legend(['train', 'test'])\n",
    "\n",
    "ax2.plot(history.history['loss'])\n",
    "ax2.plot(history.history['val_loss'])\n",
    "vline_cut = np.where(history.history['val_loss'] == np.min(history.history['val_loss']))[0][0]\n",
    "ax2.axvline(x=vline_cut, color='k', linestyle='--')\n",
    "ax2.set_title(\"Model Loss\")\n",
    "ax2.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accr = model1.evaluate(test_sequences_matrix,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = RNN()\n",
    "model2.summary()\n",
    "model2.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model2.fit(sequence_matrix,Y_train,batch_size=200,epochs=5,\n",
    "          validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(15,5))\n",
    "fig.suptitle(\"Performance of RNN Model with RELU activation, Adam optimization and Mean Squared Error\")\n",
    "ax1.plot(history.history['acc'])\n",
    "ax1.plot(history.history['val_acc'])\n",
    "vline_cut = np.where(history.history['val_acc'] == np.max(history.history['val_acc']))[0][0]\n",
    "ax1.axvline(x=vline_cut, color='k', linestyle='--')\n",
    "ax1.set_title(\"Model Accuracy\")\n",
    "ax1.legend(['train', 'test'])\n",
    "\n",
    "ax2.plot(history.history['loss'])\n",
    "ax2.plot(history.history['val_loss'])\n",
    "vline_cut = np.where(history.history['val_loss'] == np.min(history.history['val_loss']))[0][0]\n",
    "ax2.axvline(x=vline_cut, color='k', linestyle='--')\n",
    "ax2.set_title(\"Model Loss\")\n",
    "ax2.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accr = model2.evaluate(test_sequences_matrix,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNNwithSelu():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('selu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Activation('selu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = RNNwithSelu()\n",
    "model3.summary()\n",
    "model3.compile(loss='binary_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model3.fit(sequence_matrix,Y_train,batch_size=200,epochs=5,\n",
    "          validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(15,5))\n",
    "fig.suptitle(\"Performance of RNN Model with Selu activation, Binary crossentropy and RMSprop\")\n",
    "ax1.plot(history.history['acc'])\n",
    "ax1.plot(history.history['val_acc'])\n",
    "vline_cut = np.where(history.history['val_acc'] == np.max(history.history['val_acc']))[0][0]\n",
    "ax1.axvline(x=vline_cut, color='k', linestyle='--')\n",
    "ax1.set_title(\"Model Accuracy\")\n",
    "ax1.legend(['train', 'test'])\n",
    "\n",
    "ax2.plot(history.history['loss'])\n",
    "ax2.plot(history.history['val_loss'])\n",
    "vline_cut = np.where(history.history['val_loss'] == np.min(history.history['val_loss']))[0][0]\n",
    "ax2.axvline(x=vline_cut, color='k', linestyle='--')\n",
    "ax2.set_title(\"Model Loss\")\n",
    "ax2.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accr = model3.evaluate(test_sequences_matrix,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf_idf = TfidfVectorizer(ngram_range=(1,2), max_features = 50000, min_df=2)\n",
    "logit = LogisticRegression(random_state=17, n_jobs=4, C=1, verbose=True, solver='lbfgs')\n",
    "model4 = Pipeline([('tf_idf', tf_idf),('logit',logit)])\n",
    "train_texts, valid_texts, y_train, y_valid = \\\n",
    "        train_test_split(sar_acc['comment'], sar_acc['label'], random_state=17)\n",
    "history = model4.fit(train_texts,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pred = model4.predict(valid_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "accuracy_score(y_valid, valid_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
